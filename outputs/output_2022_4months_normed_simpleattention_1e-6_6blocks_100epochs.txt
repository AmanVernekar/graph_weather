cuda:1
model size: 18.219MB
Done Setup
train loss after epoch 1 is 0.17633103136169284.
val loss after epoch 1 is 0.17171811263846315.
train loss after epoch 2 is 0.17352443219799746.
val loss after epoch 2 is 0.1693479177420554.
train loss after epoch 3 is 0.17145644445952615.
val loss after epoch 3 is 0.1673952975998754.
train loss after epoch 4 is 0.16902748562003436.
val loss after epoch 4 is 0.16508640948197115.
train loss after epoch 5 is 0.16641499866780482.
val loss after epoch 5 is 0.16264295966728873.
train loss after epoch 6 is 0.16381902145712.
val loss after epoch 6 is 0.1602266242970591.
train loss after epoch 7 is 0.1613736627133269.
val loss after epoch 7 is 0.1579757523925408.
train loss after epoch 8 is 0.15905878045841268.
val loss after epoch 8 is 0.1558438098948935.
train loss after epoch 9 is 0.15682815815273085.
val loss after epoch 9 is 0.1538010429105033.
train loss after epoch 10 is 0.154774755866904.
val loss after epoch 10 is 0.15193046661822693.
train loss after epoch 11 is 0.15291877765404552.
val loss after epoch 11 is 0.1502363902071248.
train loss after epoch 12 is 0.1511623742156907.
val loss after epoch 12 is 0.14863380465818488.
train loss after epoch 13 is 0.14962715667329338.
val loss after epoch 13 is 0.14724573865532875.
train loss after epoch 14 is 0.14825568505023656.
val loss after epoch 14 is 0.1460051011780034.
train loss after epoch 15 is 0.14704172146555625.
val loss after epoch 15 is 0.1449213227176148.
train loss after epoch 16 is 0.1459819046878501.
val loss after epoch 16 is 0.14397827179535574.
train loss after epoch 17 is 0.14504914279831083.
val loss after epoch 17 is 0.14315252613438212.
train loss after epoch 18 is 0.14422943309733743.
val loss after epoch 18 is 0.14242538955548537.
train loss after epoch 19 is 0.14350381522978606.
val loss after epoch 19 is 0.14178547149767046.
train loss after epoch 20 is 0.14285979731694648.
val loss after epoch 20 is 0.14122134665756123.
train loss after epoch 21 is 0.14228919842525534.
val loss after epoch 21 is 0.1407246124809203.
train loss after epoch 22 is 0.1417792505927776.
val loss after epoch 22 is 0.14027830674920394.
train loss after epoch 23 is 0.14131890464770167.
val loss after epoch 23 is 0.1398767960946197.
train loss after epoch 24 is 0.14090307533348861.
val loss after epoch 24 is 0.13951712960134383.
train loss after epoch 25 is 0.14052313915208767.
val loss after epoch 25 is 0.139188540370568.
train loss after epoch 26 is 0.14017288131933464.
val loss after epoch 26 is 0.13888654938858488.
train loss after epoch 27 is 0.139844673499465.
val loss after epoch 27 is 0.13860274551679258.
train loss after epoch 28 is 0.13953465337031765.
val loss after epoch 28 is 0.1383363743029211.
train loss after epoch 29 is 0.13924116533445685.
val loss after epoch 29 is 0.13808491218673147.
train loss after epoch 30 is 0.13896229580829017.
val loss after epoch 30 is 0.13784737642044606.
train loss after epoch 31 is 0.13869421364445436.
val loss after epoch 31 is 0.13761943619212377.
train loss after epoch 32 is 0.138436822887314.
val loss after epoch 32 is 0.13740089219873367.
train loss after epoch 33 is 0.13818748534510011.
val loss after epoch 33 is 0.13718954441340073.
train loss after epoch 34 is 0.13794609333731625.
val loss after epoch 34 is 0.13698566453936306.
train loss after epoch 35 is 0.13771145965315792.
val loss after epoch 35 is 0.1367858808649623.
train loss after epoch 36 is 0.13748474264223326.
val loss after epoch 36 is 0.13659368803643662.
train loss after epoch 37 is 0.1372630367937841.
val loss after epoch 37 is 0.13640637153192706.
train loss after epoch 38 is 0.13704692060618023.
val loss after epoch 38 is 0.13622363446199376.
train loss after epoch 39 is 0.13683583291345522.
val loss after epoch 39 is 0.13604751342664595.
train loss after epoch 40 is 0.1366296681722528.
val loss after epoch 40 is 0.13587430605421896.
train loss after epoch 41 is 0.13642722809393154.
val loss after epoch 41 is 0.13570637758011403.
train loss after epoch 42 is 0.13622967843946657.
val loss after epoch 42 is 0.1355412231515283.
train loss after epoch 43 is 0.13603591446421648.
val loss after epoch 43 is 0.13537847566539826.
train loss after epoch 44 is 0.1358455945394541.
val loss after epoch 44 is 0.13521836608972237.
train loss after epoch 45 is 0.1356601250603011.
val loss after epoch 45 is 0.1350630613286858.
train loss after epoch 46 is 0.1354780529478663.
val loss after epoch 46 is 0.13491083487220432.
train loss after epoch 47 is 0.1352999032916207.
val loss after epoch 47 is 0.13476194546598455.
train loss after epoch 48 is 0.13512506933980867.
val loss after epoch 48 is 0.13461534565557604.
train loss after epoch 49 is 0.13495326826446935.
val loss after epoch 49 is 0.13447323886920576.
train loss after epoch 50 is 0.13478403918837245.
val loss after epoch 50 is 0.13433296209120232.
train loss after epoch 51 is 0.13461819385227405.
val loss after epoch 51 is 0.134195229443519.
train loss after epoch 52 is 0.13445421572970717.
val loss after epoch 52 is 0.1340607726217612.
train loss after epoch 53 is 0.13429359240751518.
val loss after epoch 53 is 0.1339285866883786.
train loss after epoch 54 is 0.13413525774682822.
val loss after epoch 54 is 0.13379940333897652.
train loss after epoch 55 is 0.1339794576952332.
val loss after epoch 55 is 0.13367167941254118.
train loss after epoch 56 is 0.13382648735454208.
val loss after epoch 56 is 0.13354625528597314.
train loss after epoch 57 is 0.13367538507047452.
val loss after epoch 57 is 0.13342355896273386.
train loss after epoch 58 is 0.13352692907578068.
val loss after epoch 58 is 0.13330250816500705.
train loss after epoch 59 is 0.1333799754710574.
val loss after epoch 59 is 0.13318383021523122.
train loss after epoch 60 is 0.13323564756857723.
val loss after epoch 60 is 0.1330665146689052.
train loss after epoch 61 is 0.13309374069304844.
val loss after epoch 61 is 0.13295087445041406.
train loss after epoch 62 is 0.13295374089165737.
val loss after epoch 62 is 0.13283753848594168.
train loss after epoch 63 is 0.1328162252118713.
val loss after epoch 63 is 0.13272665505823883.
train loss after epoch 64 is 0.1326806874259522.
val loss after epoch 64 is 0.13261678814888.
train loss after epoch 65 is 0.1325473359540889.
val loss after epoch 65 is 0.1325095464353976.
train loss after epoch 66 is 0.1324155247329097.
val loss after epoch 66 is 0.132405082816663.
train loss after epoch 67 is 0.13228637523164874.
val loss after epoch 67 is 0.1323009772307199.
train loss after epoch 68 is 0.13215917503755342.
val loss after epoch 68 is 0.13219866844946923.
train loss after epoch 69 is 0.13203338127779332.
val loss after epoch 69 is 0.1320978339113619.
train loss after epoch 70 is 0.13190929060311693.
val loss after epoch 70 is 0.1319970980124629.
train loss after epoch 71 is 0.13178724834793493.
val loss after epoch 71 is 0.13189834574966328.
train loss after epoch 72 is 0.13166661729153833.
val loss after epoch 72 is 0.13179920978196288.
train loss after epoch 73 is 0.13154775633623725.
val loss after epoch 73 is 0.1317037374753019.
train loss after epoch 74 is 0.13143043427875167.
val loss after epoch 74 is 0.1316084736229285.
train loss after epoch 75 is 0.13131442301367457.
val loss after epoch 75 is 0.13151585310697556.
train loss after epoch 76 is 0.13120036066362734.
val loss after epoch 76 is 0.13142356576155062.
train loss after epoch 77 is 0.13108766955372533.
val loss after epoch 77 is 0.13133261547140454.
train loss after epoch 78 is 0.1309766390213841.
val loss after epoch 78 is 0.13124401219513104.
train loss after epoch 79 is 0.13086649273571216.
val loss after epoch 79 is 0.1311561358363732.
train loss after epoch 80 is 0.13075771827838922.
val loss after epoch 80 is 0.13106862901021604.
train loss after epoch 81 is 0.13065017336293272.
val loss after epoch 81 is 0.13098242514483308.
train loss after epoch 82 is 0.13054427182988115.
val loss after epoch 82 is 0.13089816806756932.
train loss after epoch 83 is 0.1304398623932349.
val loss after epoch 83 is 0.1308139727005492.
train loss after epoch 84 is 0.1303356739643373.
val loss after epoch 84 is 0.13072882511693498.
train loss after epoch 85 is 0.13023316540608282.
val loss after epoch 85 is 0.13064538363529288.
train loss after epoch 86 is 0.130132152002893.
val loss after epoch 86 is 0.13056349964893382.
train loss after epoch 87 is 0.13003213660497415.
val loss after epoch 87 is 0.13048182209224804.
train loss after epoch 88 is 0.12993319540431625.
val loss after epoch 88 is 0.1304022361240957.
train loss after epoch 89 is 0.12983523626860818.
val loss after epoch 89 is 0.130322289450661.
train loss after epoch 90 is 0.1297378273974908.
val loss after epoch 90 is 0.1302432655154363.
train loss after epoch 91 is 0.12964166543985667.
val loss after epoch 91 is 0.13016298907282559.
train loss after epoch 92 is 0.12954657554234328.
val loss after epoch 92 is 0.13008409835722134.
train loss after epoch 93 is 0.1294523495984705.
val loss after epoch 93 is 0.1300069344756396.
train loss after epoch 94 is 0.12935907136844962.
val loss after epoch 94 is 0.12992979829078136.
train loss after epoch 95 is 0.1292667385582861.
val loss after epoch 95 is 0.12985280488172304.
train loss after epoch 96 is 0.12917509531896365.
val loss after epoch 96 is 0.12977612188652807.
train loss after epoch 97 is 0.1290840580863388.
val loss after epoch 97 is 0.12970077651350395.
train loss after epoch 98 is 0.12899401015356968.
val loss after epoch 98 is 0.1296257162871568.
train loss after epoch 99 is 0.12890492805132742.
val loss after epoch 99 is 0.1295517427927774.
train loss after epoch 100 is 0.1288167095301967.
val loss after epoch 100 is 0.12947806027596412.
Finished Training at lr=1e-06
train_losses:
[0.17633103136169284, 0.17352443219799746, 0.17145644445952615, 0.16902748562003436, 0.16641499866780482, 0.16381902145712, 0.1613736627133269, 0.15905878045841268, 0.15682815815273085, 0.154774755866904, 0.15291877765404552, 0.1511623742156907, 0.14962715667329338, 0.14825568505023656, 0.14704172146555625, 0.1459819046878501, 0.14504914279831083, 0.14422943309733743, 0.14350381522978606, 0.14285979731694648, 0.14228919842525534, 0.1417792505927776, 0.14131890464770167, 0.14090307533348861, 0.14052313915208767, 0.14017288131933464, 0.139844673499465, 0.13953465337031765, 0.13924116533445685, 0.13896229580829017, 0.13869421364445436, 0.138436822887314, 0.13818748534510011, 0.13794609333731625, 0.13771145965315792, 0.13748474264223326, 0.1372630367937841, 0.13704692060618023, 0.13683583291345522, 0.1366296681722528, 0.13642722809393154, 0.13622967843946657, 0.13603591446421648, 0.1358455945394541, 0.1356601250603011, 0.1354780529478663, 0.1352999032916207, 0.13512506933980867, 0.13495326826446935, 0.13478403918837245, 0.13461819385227405, 0.13445421572970717, 0.13429359240751518, 0.13413525774682822, 0.1339794576952332, 0.13382648735454208, 0.13367538507047452, 0.13352692907578068, 0.1333799754710574, 0.13323564756857723, 0.13309374069304844, 0.13295374089165737, 0.1328162252118713, 0.1326806874259522, 0.1325473359540889, 0.1324155247329097, 0.13228637523164874, 0.13215917503755342, 0.13203338127779332, 0.13190929060311693, 0.13178724834793493, 0.13166661729153833, 0.13154775633623725, 0.13143043427875167, 0.13131442301367457, 0.13120036066362734, 0.13108766955372533, 0.1309766390213841, 0.13086649273571216, 0.13075771827838922, 0.13065017336293272, 0.13054427182988115, 0.1304398623932349, 0.1303356739643373, 0.13023316540608282, 0.130132152002893, 0.13003213660497415, 0.12993319540431625, 0.12983523626860818, 0.1297378273974908, 0.12964166543985667, 0.12954657554234328, 0.1294523495984705, 0.12935907136844962, 0.1292667385582861, 0.12917509531896365, 0.1290840580863388, 0.12899401015356968, 0.12890492805132742, 0.1288167095301967]

val_losses:
[0.17171811263846315, 0.1693479177420554, 0.1673952975998754, 0.16508640948197115, 0.16264295966728873, 0.1602266242970591, 0.1579757523925408, 0.1558438098948935, 0.1538010429105033, 0.15193046661822693, 0.1502363902071248, 0.14863380465818488, 0.14724573865532875, 0.1460051011780034, 0.1449213227176148, 0.14397827179535574, 0.14315252613438212, 0.14242538955548537, 0.14178547149767046, 0.14122134665756123, 0.1407246124809203, 0.14027830674920394, 0.1398767960946197, 0.13951712960134383, 0.139188540370568, 0.13888654938858488, 0.13860274551679258, 0.1383363743029211, 0.13808491218673147, 0.13784737642044606, 0.13761943619212377, 0.13740089219873367, 0.13718954441340073, 0.13698566453936306, 0.1367858808649623, 0.13659368803643662, 0.13640637153192706, 0.13622363446199376, 0.13604751342664595, 0.13587430605421896, 0.13570637758011403, 0.1355412231515283, 0.13537847566539826, 0.13521836608972237, 0.1350630613286858, 0.13491083487220432, 0.13476194546598455, 0.13461534565557604, 0.13447323886920576, 0.13433296209120232, 0.134195229443519, 0.1340607726217612, 0.1339285866883786, 0.13379940333897652, 0.13367167941254118, 0.13354625528597314, 0.13342355896273386, 0.13330250816500705, 0.13318383021523122, 0.1330665146689052, 0.13295087445041406, 0.13283753848594168, 0.13272665505823883, 0.13261678814888, 0.1325095464353976, 0.132405082816663, 0.1323009772307199, 0.13219866844946923, 0.1320978339113619, 0.1319970980124629, 0.13189834574966328, 0.13179920978196288, 0.1317037374753019, 0.1316084736229285, 0.13151585310697556, 0.13142356576155062, 0.13133261547140454, 0.13124401219513104, 0.1311561358363732, 0.13106862901021604, 0.13098242514483308, 0.13089816806756932, 0.1308139727005492, 0.13072882511693498, 0.13064538363529288, 0.13056349964893382, 0.13048182209224804, 0.1304022361240957, 0.130322289450661, 0.1302432655154363, 0.13016298907282559, 0.13008409835722134, 0.1300069344756396, 0.12992979829078136, 0.12985280488172304, 0.12977612188652807, 0.12970077651350395, 0.1296257162871568, 0.1295517427927774, 0.12947806027596412]


